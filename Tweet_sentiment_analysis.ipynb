{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb063925-4539-4306-9c53-652696faea09",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS OF TWEETS ABOUT BRANDS AND PRODUCTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c770a-2eda-4a61-b5dd-f568528598ac",
   "metadata": {},
   "source": [
    ">Sentiment analysis of tweets about Google and Apple and their products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6b8f33-e650-4898-8dc3-1d37e59a871e",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center; gap: 20px;\">\n",
    "  <img src=\"google.jpg\" alt=\"Google Logo\" width=\"200\">\n",
    "  <img src=\"apple.png\" alt=\"Apple Logo\" width=\"200\">\n",
    "  <img src=\"android.jpg\" alt=\"Apple Logo\" width=\"300\">\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfef3ee-67e9-4aa4-936b-6873bc105479",
   "metadata": {},
   "source": [
    "# Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f3864-2e5d-45f2-a932-cf9e0d079790",
   "metadata": {},
   "source": [
    ">This project focuses on building a text classification model that classifies tweets into categories such as positive, negative or neutral about Google, Apple and Android and their products. This would help these companies understand how customers feel about their products, services or brand and through this information they can Improve products and services, monitor brand reputation and detect potential PR issues early."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd395b6-8fdc-4843-a07d-ddf17ff386e1",
   "metadata": {},
   "source": [
    "# 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33932dcf-887b-4c06-8b60-cea9f21392eb",
   "metadata": {},
   "source": [
    ">Google is a global technology company founded in 1998 by Larry Page and Sergey Brin, best known for its search engine that organizes and provides access to the world’s information. Headquartered in Mountain View, California, Google is now a subsidiary of Alphabet Inc. Its products and services include Google Search, Gmail, YouTube, Android, Google Maps and Google Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c191d52-e48e-4ca2-8dfc-795a046fc346",
   "metadata": {},
   "source": [
    ">Apple Inc. is an American technology company founded in 1976 by Steve Jobs, Steve Wozniak, and Ronald Wayne, headquartered in Cupertino, California. It is renowned for designing and manufacturing innovative consumer electronics, software, and online services. Apple’s flagship products include the iPhone, iPad, Mac, Apple Watch and AirPods, along with software like iOS, macOS and iCloud services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ebe44-c729-473b-8819-ede403eb9c09",
   "metadata": {},
   "source": [
    ">Android is an open-source mobile operating system developed by Google, designed primarily for touchscreen devices such as smartphones and tablets. Based on a modified version of the Linux kernel, Android offers a customizable and flexible platform that supports millions of apps through the Google Play Store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d16a94-2443-4f7b-97f0-00b311cf4da1",
   "metadata": {},
   "source": [
    "##  Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a581c1-578c-4462-83dd-77d6311c7cbc",
   "metadata": {},
   "source": [
    "\n",
    ">In today’s competitive digital marketplace, companies like Google and Apple rely heavily on public perception to maintain brand loyalty and market growth. With millions of users expressing their opinions daily on social media platforms like Twitter, it becomes increasingly challenging for companies to manually analyze and understand the sentiment behind these vast amounts of data. Sentiment analysis helps determine the type or nature of sentiment expressed in these platforms. By automating sentiment detection, companies can gain real-time insights into customer opinions, improve their products, and make data-driven marketing and business decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6727b-046f-4863-ace4-9ccc271c9bc3",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b040c72-a949-4f49-b06d-6fda15fac9b7",
   "metadata": {},
   "source": [
    "\n",
    ">- To build a text classification model that classifies tweets into categories such as positive, negative or no emotion.\n",
    ">- To preprocess the tweet data by cleaning, tokenizing and transforming text into a machine-readable format.\n",
    ">- To evaluate model performance using appropriate metrics such as accuracy and precision to ensure reliability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ffca7-dd89-49f1-bb80-6582b4339f40",
   "metadata": {},
   "source": [
    "## Metrics of Success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93652ca1-2897-4045-a985-42f0a85569bd",
   "metadata": {},
   "source": [
    ">- The model's performance will be evaluated using accuracy as the primary metric with a target accuracy of about 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4ed0b-6069-4a75-8c2c-d3682428df70",
   "metadata": {},
   "source": [
    "# 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d1d0d-ec36-444f-b53b-d8d12a86bc67",
   "metadata": {},
   "source": [
    "> The Brands and Product Emotions dataset is from a cloud-native data catalog and metadata platform, data.world. The dataset contains sentiment from Human raters in over 9,000 Tweets as positive, negative, or neither. The dataset contains 9093 rows and 3 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14edd015-0a55-4840-9712-a98990755e4e",
   "metadata": {},
   "source": [
    "## features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c219a45-a1fa-44ab-9a29-a9050daba572",
   "metadata": {},
   "source": [
    ">- `tweet_text` - The actual text from tweets\n",
    ">- `emotion_in_tweet_is_directed_at` - The brand or product the tweet is about\n",
    ">- `is_there_an_emotion_directed_at_a_brand_or_product` - Nature of sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447f4dd-927a-43ee-b9ca-a31a03b37b63",
   "metadata": {},
   "source": [
    "## Data limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3cccae-a42e-472a-8309-9453b4b74c56",
   "metadata": {},
   "source": [
    ">- Temporal relevance - The sentiments captured may be tied to specific events or time periods, reducing the dataset’s relevance for future analysis.\n",
    ">- Incomplete Data - Although the dataset contains around 9,000 rows, only about 3,000 entries in brand/product column have text. This significantly reduces the usable data and may limit the model’s ability to learn diverse patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327dddc5-394b-4a7f-b588-b49d05a12661",
   "metadata": {},
   "source": [
    "## 2.1 Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d21f67fd-2ddb-482a-968a-207b351a8020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae522d3f-561f-4fd8-aeab-632e81e9cb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a4d93f-4472-4b05-ac8b-d8cd59114a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:  9093\n",
      "Columns:  3\n"
     ]
    }
   ],
   "source": [
    "# shape of dataset\n",
    "print(\"Rows: \", tweet_df.shape[0])\n",
    "print(\"Columns: \", tweet_df.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d164c4b-eb82-4c71-a430-8b3b9f925fc8",
   "metadata": {},
   "source": [
    "## 2.2 Information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c61693-732e-48ce-b2df-dc1f349fd8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# dataset information\n",
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd352d6-b9be-4fb7-a691-aba509b76293",
   "metadata": {},
   "source": [
    "## 2.3 Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1da2a5e-c5ca-4b49-ae07-7bc47f71f32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 5803 missing values\n"
     ]
    }
   ],
   "source": [
    "# checking for null values\n",
    "print(\"The dataset has\", tweet_df.isna().sum().sum(), \"missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8890b-97c8-4d90-9e53-19f8c30cb145",
   "metadata": {},
   "source": [
    "## 2.4 Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a6f4c80-b55e-482b-b59e-c5f6437bcd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 27 duplicates\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset has\", tweet_df['tweet_text'].duplicated().sum(), \"duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4603e83-ced3-4881-8d14-0c346551b5ff",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18a36b-5e71-468f-81e6-102913ee458d",
   "metadata": {},
   "source": [
    "## 3.1 Handling missing values and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d163f5e3-3f39-4535-a63d-6bfee595c9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                               1\n",
       "emotion_in_tweet_is_directed_at                       5802\n",
       "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking distribution of null values\n",
    "tweet_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99603715-e11b-466a-846d-1d1cbb993ab3",
   "metadata": {},
   "source": [
    "Since we only have one empty row in 'tweet_text' column we drop the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b0abdae-654c-47aa-8661-8fb615ff63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping null values in 'tweet_text' column\n",
    "tweet_df.dropna(subset=['tweet_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82fa722a-b1bc-43e6-9f20-fafa4b9e3fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                               0\n",
       "emotion_in_tweet_is_directed_at                       5801\n",
       "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a36c83d2-6806-45f1-a978-b76da859d537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['iPhone', 'iPad or iPhone App', 'iPad', 'Google', nan, 'Android',\n",
       "       'Apple', 'Android App', 'Other Google product or service',\n",
       "       'Other Apple product or service'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking all the categories in 'emotion_in_tweet_is_directed_at' column \n",
    "tweet_df['emotion_in_tweet_is_directed_at'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161d0fb-93c0-4d83-9591-1b54326aa918",
   "metadata": {},
   "source": [
    "Since we have 5801 empty rows in 'emotion_in_tweet_is_directed_at' column If we drop all of them that could be half of our dataset gone meaning fewer examples for our model to learn from, so instead we replace the NaN with \"Unknown\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfc65736-8950-4d00-836d-cb73a0fdcff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_31776\\2951143570.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  tweet_df['emotion_in_tweet_is_directed_at'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# filling in the null values with 'Unknown' category\n",
    "tweet_df['emotion_in_tweet_is_directed_at'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08ab871e-bbd2-4e63-b112-fa2f7ce81c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Apple product or service', 'Google product or service', 'Unknown'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df['emotion_in_tweet_is_directed_at'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca0447a6-c0f4-4438-8a3f-b6417e64cd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                            0\n",
       "emotion_in_tweet_is_directed_at                       0\n",
       "is_there_an_emotion_directed_at_a_brand_or_product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e463a20d-5ecb-43a7-96a6-09071d21a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicate tweet texts\n",
    "tweet_df = tweet_df.drop_duplicates(subset=['tweet_text'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ce56a31-e2f6-4833-a4c1-b0f1beca28e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset has\", tweet_df['tweet_text'].duplicated().sum(), \"duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b359810-51aa-4338-9c4c-63bff15db0bc",
   "metadata": {},
   "source": [
    "## 3.2 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5dd60-a762-4c1c-9334-9123a5d84846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b4cf84a-ce3e-4d6a-a386-6bc2afb58a35",
   "metadata": {},
   "source": [
    "## 3.3 Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfe44b7f-0c06-4cc8-82a4-db27bf0c3ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the categories into 3 \n",
    "new_categories = {\n",
    "    'iPad or iPhone App': 'Apple product or service',\n",
    "    'iPad': 'Apple product or service',\n",
    "    'iPhone': 'Apple product or service',\n",
    "    'Apple': 'Apple product or service',\n",
    "    'Other Apple product or service': 'Apple product or service',\n",
    "\n",
    "    'Android': 'Google product or service',\n",
    "    'Android App': 'Google product or service',\n",
    "    'Google': 'Google product or service',\n",
    "    'Other Google product or service': 'Google product or service'\n",
    "    }\n",
    "\n",
    "tweet_df['emotion_in_tweet_is_directed_at'] = tweet_df['emotion_in_tweet_is_directed_at'].map(new_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a165d24-438b-4782-a0f7-c9c04c292867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Apple product or service', 'Google product or service', 'Unknown'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df['emotion_in_tweet_is_directed_at'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3259718-3795-4981-b43d-4675fbbd78af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_there_an_emotion_directed_at_a_brand_or_product\n",
       "No emotion toward brand or product    5372\n",
       "Positive emotion                      2968\n",
       "Negative emotion                       569\n",
       "I can't tell                           156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "befb5bfa-9f8d-4e81-ad64-db97b4da600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the sentiment categories into 3\n",
    "emotion = {\n",
    "    'Positive emotion': 'Positive emotion',\n",
    "    'Negative emotion': 'Negative emotion',\n",
    "    'No emotion toward brand or product': 'Neutral or unclear sentiment',\n",
    "    \"I can't tell\": 'Neutral or unclear sentiment'\n",
    "\n",
    "    }\n",
    "\n",
    "tweet_df['is_there_an_emotion_directed_at_a_brand_or_product'] = tweet_df['is_there_an_emotion_directed_at_a_brand_or_product'].map(emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab699c-1300-4176-bce7-bc2b92785972",
   "metadata": {},
   "source": [
    "Text preprocessing steps\n",
    "\t                 \t         \n",
    "1. Lowercasing\t        \t\n",
    "2. Remove punctuation\t \t       \n",
    "3. Tokenization\t         \t\n",
    "4. Remove stopwords\t     \t\n",
    "5. Lemmatization\t     \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89d65576-7ea1-4b8e-b9ec-05c8f99a3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an intance of the RegexpTokenizer with the variable name `tokenizer`\n",
    "tokenizer = RegexpTokenizer(r\"(?u)\\w{3,}\")\n",
    "\n",
    "# creating an instance of WordNetLemmatizer\n",
    "lemmatizer =  WordNetLemmatizer()\n",
    "\n",
    "# creating a list of stopwords in the english language\n",
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc27b6f5-449e-4601-b787-bd6d6bc62c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to perform the preprocessing\n",
    "def preprocess(text, tokenizer, lemmatizer, stopwords_list):\n",
    "    # lowercase the text\n",
    "    text = text.lower()\n",
    "    # remove punctuation, symbols and tokenize the text\n",
    "    text = tokenizer.tokenize(text)\n",
    "    # remove stopwords\n",
    "    text = [word for word in text if word not in stopwords_list]\n",
    "    # lemmatize the text\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    # return the preprocessed text as single string\n",
    "    return \" \".join(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43b7f6df-24a6-4e1f-84c5-7ab85f8ccc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spin play ipad launch party hanging mention mention sxsw mention cedar street courtyard link'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing our function on a small sample\n",
    "sample = 'Spin Play iPad launch Party. Hanging with @mention and @mention #sxsw (@mention Cedar Street Courtyard) {link}'\n",
    "preprocess(sample, tokenizer, lemmatizer, stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c30592c-a8f2-4ca5-b624-09ab9c3f8e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing our tweet text and creating a new column for the cleaned text\n",
    "tweet_df['cleaned_text'] = tweet_df['tweet_text'].apply(lambda x: preprocess(x, tokenizer, lemmatizer, stopwords_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0bbac09-d767-408e-a90a-3d5e4290d043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Apple product or service</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 iphone hr tweeting rise_austin dead n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Apple product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know fludapp awesome ipad iphone app ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Apple product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Apple product or service</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw hope year festival crashy year iphone app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri sxsw marissa mayer g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0        Apple product or service   \n",
       "1        Apple product or service   \n",
       "2        Apple product or service   \n",
       "3        Apple product or service   \n",
       "4       Google product or service   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                   Negative emotion   \n",
       "1                                   Positive emotion   \n",
       "2                                   Positive emotion   \n",
       "3                                   Negative emotion   \n",
       "4                                   Positive emotion   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  wesley83 iphone hr tweeting rise_austin dead n...  \n",
       "1  jessedee know fludapp awesome ipad iphone app ...  \n",
       "2                swonderlin wait ipad also sale sxsw  \n",
       "3  sxsw hope year festival crashy year iphone app...  \n",
       "4  sxtxstate great stuff fri sxsw marissa mayer g...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05291b55-9e54-47d4-a7bf-907bc2d6523b",
   "metadata": {},
   "source": [
    "## Frequency Distributions\n",
    "\n",
    "Now that we've done some basic cleaning and tokenization, let's go ahead and create a `Frequency Distribution`to see the number of times each word is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d305408e-106b-4001-9f38-c6c1d700b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all the words into one big list\n",
    "all_words = \" \".join(tweet_df['cleaned_text']).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34f01bc9-7bb8-4463-8c5e-5fa9d45047e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sxsw', 9600),\n",
       " ('mention', 7107),\n",
       " ('link', 4305),\n",
       " ('google', 2653),\n",
       " ('ipad', 2513),\n",
       " ('apple', 2333),\n",
       " ('quot', 1696),\n",
       " ('iphone', 1585),\n",
       " ('store', 1523),\n",
       " ('new', 1084),\n",
       " ('austin', 971),\n",
       " ('amp', 827),\n",
       " ('app', 825),\n",
       " ('launch', 683),\n",
       " ('circle', 683),\n",
       " ('social', 660),\n",
       " ('pop', 599),\n",
       " ('android', 596),\n",
       " ('today', 577),\n",
       " ('network', 467)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting how often each word appears\n",
    "all_words_freqdist = FreqDist(all_words)\n",
    "all_words_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18b4d6-74b4-41d3-88bb-962d56d4542f",
   "metadata": {},
   "source": [
    "Some words like 'sxsw', 'mention', 'link', 'rt', 'amp', 'quot' do not add meaning to our text so we add them to our stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f417cdb9-5f13-4ead-bd76-a18652ba42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add custom meaningless tokens\n",
    "custom_stopwords = {'sxsw', 'mention', 'link', 'rt', 'amp', 'quot'}\n",
    "\n",
    "# merge them\n",
    "stopwords_list.extend(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f481c89-ac4b-4e74-b9a5-40bfc13756d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we rerun the function\n",
    "tweet_df['cleaned_text'] = tweet_df['tweet_text'].apply(lambda x: preprocess(x, tokenizer, lemmatizer, stopwords_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db64cbb5-e93b-4a21-9781-27846c5be989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('google', 2653),\n",
       " ('ipad', 2513),\n",
       " ('apple', 2333),\n",
       " ('iphone', 1585),\n",
       " ('store', 1523),\n",
       " ('new', 1084),\n",
       " ('austin', 971),\n",
       " ('app', 825),\n",
       " ('launch', 683),\n",
       " ('circle', 683),\n",
       " ('social', 660),\n",
       " ('pop', 599),\n",
       " ('android', 596),\n",
       " ('today', 577),\n",
       " ('network', 467),\n",
       " ('ipad2', 464),\n",
       " ('get', 456),\n",
       " ('line', 448),\n",
       " ('via', 436),\n",
       " ('party', 401)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words_freqdist = FreqDist(all_words)\n",
    "all_words_freqdist.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae74297-ee4a-46cf-a318-ef02c8401746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
